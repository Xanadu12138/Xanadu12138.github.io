<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Xanadu</title>
  
  
  <link href="https://xanadu12138.github.io/atom.xml" rel="self"/>
  
  <link href="https://xanadu12138.github.io/"/>
  <updated>2021-07-21T13:09:35.452Z</updated>
  <id>https://xanadu12138.github.io/</id>
  
  <author>
    <name>Yucong Dai</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Summary of approaches used in person Re-Id task.(part 1)</title>
    <link href="https://xanadu12138.github.io/2021/07/21/Re-Id/"/>
    <id>https://xanadu12138.github.io/2021/07/21/Re-Id/</id>
    <published>2021-07-21T12:57:10.000Z</published>
    <updated>2021-07-21T13:09:35.452Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Deep-ReID-Architecture-Types"><a href="#Deep-ReID-Architecture-Types" class="headerlink" title="Deep ReID Architecture Types"></a>Deep ReID Architecture Types</h2><h3 id="Classification-Models"><a href="#Classification-Models" class="headerlink" title="Classification Models"></a>Classification Models</h3><p>Classification models consider ReID as a multi-class classification problem. Those models use the softmax loss to predict the class of an input query. Softmax loss encourages the separation of different classes but struggles with large intra-class variations.</p><p>Several methods overcome the inability of softmax loss to handle intra-class variations by introducing new loss.</p><ul><li><p>In “A loss combination based deep model for person re-identification”, Zhu et al. conjunct with center loss which was originally used for facial recognition. AUthors train a CNN with the proposed combination of softmax and center loss to extract discriminative features.<br><img src="fig1.png" alt="Fig1" title="CNN training based on combination of Softmax and centet loss."></p></li><li><p>In “SphereRe-Id: Deep hypersphere manifold embedding for person re-identification”, Fan et al. use a multi-loss training setup having a combination of softmax loss, center loss and “inter-center loss”. While the softmax loss differentiates between different identity samples, the center loss pull the same class identities closer to their center and the inter-center loss push the center of different identity away from another.<br><img src="fig2.png" alt="Fig2"></p></li></ul><h3 id="Verification-Models"><a href="#Verification-Models" class="headerlink" title="Verification Models"></a>Verification Models</h3><p>Verification Models consider ReID to be a binary-classification problem. However, those models suffer from the class imbalance problem.</p><h3 id="Triplet-Based-Re-Id-Models"><a href="#Triplet-Based-Re-Id-Models" class="headerlink" title="Triplet Based Re-Id Models"></a>Triplet Based Re-Id Models</h3><p>Triplet models for Re-Id take triplet input units. Each triplet unit contains three image samples: the anchor(have same identity as the anchor), a positive sample and a negative sample(different identity from the anchor). The triplet loss is trained to keep the Euclidean distance between anchor and positive sample less than anchor and negative sample.<br><img src="fig3.png" alt="fig3"></p><p>Traditional triplet loss has convergence issus.</p><h3 id="part-based-Re-Id-Models"><a href="#part-based-Re-Id-Models" class="headerlink" title="part-based Re-Id Models"></a>part-based Re-Id Models</h3><p>Part-based Re-Id methods extract different image regions to find discriminative part-level features. Thoese models have better performence in handling small inter-class variations such as identifying different people wearing same color clothes due to their superior discrimination capability based on finer part-level cues which are usually suppressed while extracting global features.</p><p>In “Multi-level attention model for person re-identification”, Yan et al. propose a feature attention block for part-based Re-Id. The authors slice features maps into spatial features and assign them weight to highlight the important part regions.<br><img src="fig4.png" alt="fig4"></p><h3 id="Attention-Based-Re-Id-Models"><a href="#Attention-Based-Re-Id-Models" class="headerlink" title="Attention-Based Re-Id Models"></a>Attention-Based Re-Id Models</h3><p>Attention Modules focus on extracting regions containing highly discriminative features while ignoring other regions having little or no discriminative capability.<br><img src="fig5.png" alt="fig5"></p><h2 id="Re-Id-challenges-and-solutions"><a href="#Re-Id-challenges-and-solutions" class="headerlink" title="Re-Id challenges and solutions"></a>Re-Id challenges and solutions</h2><p>The task of person re-identification has faced several challenges like sample variations in view, pose, lightning and scale, partial or complete occlusion, background clutter etc.<br><img src="fig6.png" alt="fig6"></p><ul><li><p>Several deep Re-Id contributions have aimed to develop robust methodoligies against these Re-Id challenges.</p></li><li><p>Skeleton joints data and clothe colors produce pose and lightning invariance, learning view-specific representations for view invariance, utilizing foreground attentive network to suppress noisy background, convolving with multi-scale input to obtain scale invariant features and using pose estimation to achieve pose invariance are some of efforts to overcome these challenges.</p></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;Deep-ReID-Architecture-Types&quot;&gt;&lt;a href=&quot;#Deep-ReID-Architecture-Types&quot; class=&quot;headerlink&quot; title=&quot;Deep ReID Architecture Types&quot;&gt;&lt;/a&gt;De</summary>
      
    
    
    
    <category term="Note" scheme="https://xanadu12138.github.io/categories/Note/"/>
    
    
    <category term="Re-Id" scheme="https://xanadu12138.github.io/tags/Re-Id/"/>
    
    <category term="Deep learning" scheme="https://xanadu12138.github.io/tags/Deep-learning/"/>
    
  </entry>
  
</feed>
