<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Xanadu</title>
  
  
  <link href="https://xanadu12138.github.io/atom.xml" rel="self"/>
  
  <link href="https://xanadu12138.github.io/"/>
  <updated>2021-07-27T09:58:21.314Z</updated>
  <id>https://xanadu12138.github.io/</id>
  
  <author>
    <name>Yucong Dai</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Locally Aware Transformer</title>
    <link href="https://xanadu12138.github.io/2021/07/27/la-transformer/"/>
    <id>https://xanadu12138.github.io/2021/07/27/la-transformer/</id>
    <published>2021-07-27T08:21:40.000Z</published>
    <updated>2021-07-27T09:58:21.314Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Review-of-Person-Re-Identification-with-a-Locally-Aware-Transformer"><a href="#Review-of-Person-Re-Identification-with-a-Locally-Aware-Transformer" class="headerlink" title="Review of Person Re-Identification with a Locally Aware Transformer"></a>Review of Person Re-Identification with a Locally Aware Transformer</h2><h3 id="Summary-in-one-sentence"><a href="#Summary-in-one-sentence" class="headerlink" title="Summary in one sentence."></a>Summary in one sentence.</h3><p>Sharma et al. propused a locally aware transormer inspired by Parts-based Convolution Baseline(PCB) and ViT(Vision Transformer) as well as a fine-tunning strategy which further improve Re-ID accuracy</p><h3 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h3><p>Person Re-Identification task:</p><ul><li>Person Re-ID task includes object dectation and image retrival tasks in earily researches. It separates the tasks and focuses on finding the most similar images in gallery according to the given querry image in recent researches.</li><li>I sammarized some common approaches in my last <a href="https://xanadu12138.github.io/2021/07/21/Re-Id/">post</a>, you can check it before going on.</li><li>Extant problem: Exiting approaches only focus on the classification token, and local tokens which are also outputs of the transformer encoder are able to improve the performance of many computer vision tasks.</li></ul><p>The LA-transformer utilize local tokens as an enhanced feature representation of the original image. Inspired by the PCB which partitions the feature vector into six vertical regions and constructs an ensemble of regional classifiers with a voting strategy to determine the predicted class label, LA-transformer adopt a PCB-like strategy to fine-tunning on person Re-Id. A limitation of PCB is that each regional classifier ignores the global information which is also very important for recognition and identification. Thus, LA-transformer combines the CLS token and local token to improve performance.</p><h2 id="Architecture-of-LA-transformer"><a href="#Architecture-of-LA-transformer" class="headerlink" title="Architecture of LA-transformer"></a>Architecture of LA-transformer</h2><p><img src="./top.png" alt="img"><br>The backbone ViT excludes MLP Head and classifier are same as the original ViT. The novel Locally Aware Network is attached on the backbone network. As the image illustrates that Local feature plus global CLS token to form Globally Enhanced Local Tokens and seprates them into 14 parts. After average pooling, each part of GELT are feed to an independed classifier as PCB’s voting strategy. Eventually, using softmax loss to find the optimal feature representation of images.</p><h2 id="Fine-tunning-strategy"><a href="#Fine-tunning-strategy" class="headerlink" title="Fine-tunning strategy."></a>Fine-tunning strategy.</h2><p>Person re-ID datasets are known for their small size and training a transformer on these datasets can quickly lead to overfitting. ViT was pre-trained on ImageNet, and then fine-tuned on person re-ID datasets.</p><p>In blockwise fine-tuning, all transformer blocks are frozen in the start<br>except for the bottleneck model. After every t epochs (where t is a hyper-parameter), one additional transformer encoder block is unfrozen and the learning rate is reduced as described by algorithm1. The learning rate decay helps in reducing the gradient flow in the subsequent layers hence prevent abrupt weight updates.<br><img src="./alg1.png" alt="img"></p><h2 id="Test-architecture"><a href="#Test-architecture" class="headerlink" title="Test architecture"></a>Test architecture</h2><p>In the test period, remove the classifiers and use the GELT as a image’s feature representation. Given a querry image, search the most similar images in gallery by the features learned by models.</p>]]></content>
    
    
    <summary type="html">Reproduction of Person Re-Identification with a Locally Aware Transformer.</summary>
    
    
    
    <category term="Note" scheme="https://xanadu12138.github.io/categories/Note/"/>
    
    
    <category term="Re-Id" scheme="https://xanadu12138.github.io/tags/Re-Id/"/>
    
    <category term="Deep learning" scheme="https://xanadu12138.github.io/tags/Deep-learning/"/>
    
  </entry>
  
  <entry>
    <title>Summary of approaches used in person Re-Id task.(part 1)</title>
    <link href="https://xanadu12138.github.io/2021/07/21/Re-Id/"/>
    <id>https://xanadu12138.github.io/2021/07/21/Re-Id/</id>
    <published>2021-07-21T12:57:10.000Z</published>
    <updated>2021-07-25T02:49:22.387Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Deep-ReID-Architecture-Types"><a href="#Deep-ReID-Architecture-Types" class="headerlink" title="Deep ReID Architecture Types"></a>Deep ReID Architecture Types</h2><h3 id="Classification-Models"><a href="#Classification-Models" class="headerlink" title="Classification Models"></a>Classification Models</h3><p>Classification models consider ReID as a multi-class classification problem. Those models use the softmax loss to predict the class of an input query. Softmax loss encourages the separation of different classes but struggles with large intra-class variations.</p><p>Several methods overcome the inability of softmax loss to handle intra-class variations by introducing new loss.</p><ul><li><p>In “A loss combination based deep model for person re-identification”, Zhu et al. conjunct with center loss which was originally used for facial recognition. AUthors train a CNN with the proposed combination of softmax and center loss to extract discriminative features.<br><img src="fig1.png" alt="Fig1" title="CNN training based on combination of Softmax and centet loss."></p></li><li><p>In “SphereRe-Id: Deep hypersphere manifold embedding for person re-identification”, Fan et al. use a multi-loss training setup having a combination of softmax loss, center loss and “inter-center loss”. While the softmax loss differentiates between different identity samples, the center loss pull the same class identities closer to their center and the inter-center loss push the center of different identity away from another.<br><img src="fig2.png" alt="Fig2"></p></li></ul><h3 id="Verification-Models"><a href="#Verification-Models" class="headerlink" title="Verification Models"></a>Verification Models</h3><p>Verification Models consider ReID to be a binary-classification problem. However, those models suffer from the class imbalance problem.</p><h3 id="Triplet-Based-Re-Id-Models"><a href="#Triplet-Based-Re-Id-Models" class="headerlink" title="Triplet Based Re-Id Models"></a>Triplet Based Re-Id Models</h3><p>Triplet models for Re-Id take triplet input units. Each triplet unit contains three image samples: the anchor(have same identity as the anchor), a positive sample and a negative sample(different identity from the anchor). The triplet loss is trained to keep the Euclidean distance between anchor and positive sample less than anchor and negative sample.<br><img src="fig3.png" alt="fig3"></p><p>Traditional triplet loss has convergence issus.</p><h3 id="part-based-Re-Id-Models"><a href="#part-based-Re-Id-Models" class="headerlink" title="part-based Re-Id Models"></a>part-based Re-Id Models</h3><p>Part-based Re-Id methods extract different image regions to find discriminative part-level features. Thoese models have better performence in handling small inter-class variations such as identifying different people wearing same color clothes due to their superior discrimination capability based on finer part-level cues which are usually suppressed while extracting global features.</p><p>In “Multi-level attention model for person re-identification”, Yan et al. propose a feature attention block for part-based Re-Id. The authors slice features maps into spatial features and assign them weight to highlight the important part regions.<br><img src="fig4.png" alt="fig4"></p><h3 id="Attention-Based-Re-Id-Models"><a href="#Attention-Based-Re-Id-Models" class="headerlink" title="Attention-Based Re-Id Models"></a>Attention-Based Re-Id Models</h3><p>Attention Modules focus on extracting regions containing highly discriminative features while ignoring other regions having little or no discriminative capability.<br><img src="fig5.png" alt="fig5"></p><h2 id="Re-Id-challenges-and-solutions"><a href="#Re-Id-challenges-and-solutions" class="headerlink" title="Re-Id challenges and solutions"></a>Re-Id challenges and solutions</h2><p>The task of person re-identification has faced several challenges like sample variations in view, pose, lightning and scale, partial or complete occlusion, background clutter etc.<br><img src="fig6.png" alt="fig6"></p><ul><li><p>Several deep Re-Id contributions have aimed to develop robust methodoligies against these Re-Id challenges.</p></li><li><p>Skeleton joints data and clothe colors produce pose and lightning invariance, learning view-specific representations for view invariance, utilizing foreground attentive network to suppress noisy background, convolving with multi-scale input to obtain scale invariant features and using pose estimation to achieve pose invariance are some of efforts to overcome these challenges.</p></li></ul>]]></content>
    
    
    <summary type="html">Introduction to common solutions of person Re-Id task.</summary>
    
    
    
    <category term="Note" scheme="https://xanadu12138.github.io/categories/Note/"/>
    
    
    <category term="Re-Id" scheme="https://xanadu12138.github.io/tags/Re-Id/"/>
    
    <category term="Deep learning" scheme="https://xanadu12138.github.io/tags/Deep-learning/"/>
    
  </entry>
  
</feed>
